"""
æ·±åº¦å­¦ä¹ MLPæ¨¡å—æµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯æ·±åº¦å­¦ä¹ MLPæ¨¡å—çš„åŠŸèƒ½
"""

import pandas as pd
import numpy as np
from pathlib import Path
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.dl_mlp import DeepLearningMLP, MLPModel, MLPTrainer
from src.features import build_features

def test_mlp_model():
    """
    æµ‹è¯•MLPæ¨¡å‹çš„åŸºæœ¬åŠŸèƒ½
    """
    print("="*60)
    print("MLPæ¨¡å‹æµ‹è¯•")
    print("="*60)
    
    # æµ‹è¯•æ¨¡å‹åˆ›å»º
    print("\n1. æµ‹è¯•MLPæ¨¡å‹åˆ›å»º...")
    try:
        model = MLPModel(
            input_dim=100,
            hidden_dims=[256, 128, 64],
            dropout_rate=0.3,
            activation='relu'
        )
        print(f"âœ… MLPæ¨¡å‹åˆ›å»ºæˆåŠŸ")
        print(f"   è¾“å…¥ç»´åº¦: {model.network[0].in_features}")
        print(f"   è¾“å‡ºç»´åº¦: {model.network[-1].out_features}")
        print(f"   æ€»å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    except Exception as e:
        print(f"âŒ MLPæ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    print("\n2. æµ‹è¯•å‰å‘ä¼ æ’­...")
    try:
        import torch
        x = torch.randn(32, 100)  # æ‰¹æ¬¡å¤§å°ä¸º32ï¼Œç‰¹å¾ç»´åº¦100
        output = model(x)
        print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"   è¾“å…¥å½¢çŠ¶: {x.shape}")
        print(f"   è¾“å‡ºå½¢çŠ¶: {output.shape}")
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        return False
    
    return True

def test_mlp_trainer():
    """
    æµ‹è¯•MLPè®­ç»ƒå™¨çš„åŸºæœ¬åŠŸèƒ½
    """
    print("\n" + "="*60)
    print("MLPè®­ç»ƒå™¨æµ‹è¯•")
    print("="*60)
    
    # æµ‹è¯•è®­ç»ƒå™¨åˆ›å»º
    print("\n1. æµ‹è¯•MLPè®­ç»ƒå™¨åˆ›å»º...")
    try:
        model = MLPModel(input_dim=50, hidden_dims=[64, 32], dropout_rate=0.2)
        trainer = MLPTrainer(
            model=model,
            learning_rate=1e-3,
            weight_decay=1e-4,
            patience=10,
            max_epochs=50
        )
        print(f"âœ… MLPè®­ç»ƒå™¨åˆ›å»ºæˆåŠŸ")
        print(f"   è®¾å¤‡: {trainer.device}")
        print(f"   å­¦ä¹ ç‡: {trainer.learning_rate}")
        print(f"   æœ€å¤§è½®æ•°: {trainer.max_epochs}")
    except Exception as e:
        print(f"âŒ MLPè®­ç»ƒå™¨åˆ›å»ºå¤±è´¥: {e}")
        return False
    
    return True

def test_deep_learning_mlp():
    """
    æµ‹è¯•æ·±åº¦å­¦ä¹ MLPä¸»ç±»çš„åŠŸèƒ½
    """
    print("\n" + "="*60)
    print("æ·±åº¦å­¦ä¹ MLPä¸»ç±»æµ‹è¯•")
    print("="*60)
    
    # æµ‹è¯•ä¸»ç±»åˆ›å»º
    print("\n1. æµ‹è¯•æ·±åº¦å­¦ä¹ MLPä¸»ç±»åˆ›å»º...")
    try:
        mlp = DeepLearningMLP(random_seed=42, n_splits=5)
        print(f"âœ… æ·±åº¦å­¦ä¹ MLPä¸»ç±»åˆ›å»ºæˆåŠŸ")
        print(f"   éšæœºç§å­: {mlp.random_seed}")
        print(f"   æŠ˜æ•°: {mlp.n_splits}")
        print(f"   æ¨¡å‹é…ç½®: {mlp.model_config}")
        print(f"   è®­ç»ƒé…ç½®: {mlp.training_config}")
    except Exception as e:
        print(f"âŒ æ·±åº¦å­¦ä¹ MLPä¸»ç±»åˆ›å»ºå¤±è´¥: {e}")
        return False
    
    return True

def test_data_preparation():
    """
    æµ‹è¯•æ•°æ®å‡†å¤‡åŠŸèƒ½
    """
    print("\n" + "="*60)
    print("æ•°æ®å‡†å¤‡æµ‹è¯•")
    print("="*60)
    
    # æµ‹è¯•æ•°æ®åŠ è½½
    print("\n1. æµ‹è¯•æ•°æ®åŠ è½½...")
    from config import PROCESSED_DATA_DIR
    data_path = PROCESSED_DATA_DIR / "hernia_clean.csv"
    
    if not data_path.exists():
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
        print("è¯·å…ˆè¿è¡Œç‰¹å¾å·¥ç¨‹æ¨¡å—ç”Ÿæˆæ•°æ®")
        return False
    
    df = pd.read_csv(data_path)
    print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {df.shape}")
    
    # æµ‹è¯•ç‰¹å¾å·¥ç¨‹
    print("\n2. æµ‹è¯•ç‰¹å¾å·¥ç¨‹...")
    try:
        X, y, metadata = build_features(df, target_col="duration_min", use_log_target=True)
        print(f"âœ… ç‰¹å¾å·¥ç¨‹æˆåŠŸ: X={X.shape}, y={y.shape}")
    except Exception as e:
        print(f"âŒ ç‰¹å¾å·¥ç¨‹å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•æ•°æ®å‡†å¤‡
    print("\n3. æµ‹è¯•æ•°æ®å‡†å¤‡...")
    try:
        mlp = DeepLearningMLP(random_seed=42, n_splits=5)
        X_tensor, y_tensor, metadata = mlp.prepare_data(df, target_col="duration_min", use_log_target=True)
        print(f"âœ… æ•°æ®å‡†å¤‡æˆåŠŸ: X={X_tensor.shape}, y={y_tensor.shape}")
    except Exception as e:
        print(f"âŒ æ•°æ®å‡†å¤‡å¤±è´¥: {e}")
        return False
    
    return True

def test_model_configurations():
    """
    æµ‹è¯•æ¨¡å‹é…ç½®çš„åˆç†æ€§
    """
    print("\n" + "="*60)
    print("æ¨¡å‹é…ç½®æµ‹è¯•")
    print("="*60)
    
    mlp = DeepLearningMLP(random_seed=42, n_splits=5)
    
    print("\næ¨¡å‹é…ç½®:")
    for key, value in mlp.model_config.items():
        print(f"  {key}: {value}")
    
    print("\nè®­ç»ƒé…ç½®:")
    for key, value in mlp.training_config.items():
        print(f"  {key}: {value}")
    
    # æ£€æŸ¥é…ç½®åˆç†æ€§
    print(f"\né…ç½®æ£€æŸ¥:")
    if mlp.training_config['max_epochs'] <= 100:
        print(f"  âœ… æœ€å¤§è½®æ•°ç¬¦åˆè¦æ±‚ (â‰¤100): {mlp.training_config['max_epochs']}")
    else:
        print(f"  âŒ æœ€å¤§è½®æ•°è¶…è¿‡è¦æ±‚ (>100): {mlp.training_config['max_epochs']}")
    
    if mlp.training_config['patience'] > 0:
        print(f"  âœ… Early stoppingè€å¿ƒå€¼åˆç†: {mlp.training_config['patience']}")
    else:
        print(f"  âŒ Early stoppingè€å¿ƒå€¼ä¸åˆç†: {mlp.training_config['patience']}")
    
    if mlp.model_config['dropout_rate'] > 0 and mlp.model_config['dropout_rate'] < 1:
        print(f"  âœ… Dropoutç‡åˆç†: {mlp.model_config['dropout_rate']}")
    else:
        print(f"  âŒ Dropoutç‡ä¸åˆç†: {mlp.model_config['dropout_rate']}")

if __name__ == "__main__":
    print("å¼€å§‹æ·±åº¦å­¦ä¹ MLPæ¨¡å—æµ‹è¯•...")
    
    # è¿è¡ŒåŠŸèƒ½æµ‹è¯•
    success = True
    
    # æµ‹è¯•MLPæ¨¡å‹
    if not test_mlp_model():
        success = False
    
    # æµ‹è¯•MLPè®­ç»ƒå™¨
    if not test_mlp_trainer():
        success = False
    
    # æµ‹è¯•æ·±åº¦å­¦ä¹ MLPä¸»ç±»
    if not test_deep_learning_mlp():
        success = False
    
    # æµ‹è¯•æ•°æ®å‡†å¤‡
    if not test_data_preparation():
        success = False
    
    # æµ‹è¯•æ¨¡å‹é…ç½®
    test_model_configurations()
    
    if success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ·±åº¦å­¦ä¹ MLPæ¨¡å—å·²å‡†å¤‡å°±ç»ª")
        print("\nä¸‹ä¸€æ­¥:")
        print("1. è¿è¡Œå®Œæ•´è®­ç»ƒ: python3 dl_mlp.py")
        print("2. æŸ¥çœ‹ç”Ÿæˆçš„è®­ç»ƒæ›²çº¿å’Œæ¨¡å‹æƒé‡")
        print("3. åˆ†æOOFé¢„æµ‹ç»“æœ")
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        sys.exit(1)

