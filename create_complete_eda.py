#!/usr/bin/env python3
"""
创建完整EDA笔记本的脚本 - Phase 2
"""

import json

# 完整的EDA笔记本内容
notebook_content = {
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 手术时长预测 - 探索性数据分析 (EDA) - Phase 2\n",
                "\n",
                "## 目标\n",
                "理解数据形态，验证问题定义与评估度量\n",
                "\n",
                "## 主要任务\n",
                "1. 统计：样本量、缺失率、数值分布、类别基数\n",
                "2. 目标分布：duration_min 直方图 & 箱线图（考虑log1p变换）\n",
                "3. 相关性：数值特征与 duration_min 的皮尔森/斯皮尔曼\n",
                "4. 漏洞排查：是否存在事后变量（泄漏）\n",
                "5. 评估指标定义：MAE、RMSE、R²、MedAE"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 导入必要的库\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# 设置中文字体\n",
                "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']\n",
                "plt.rcParams['axes.unicode_minus'] = False\n",
                "\n",
                "# 设置随机种子\n",
                "np.random.seed(42)\n",
                "\n",
                "# 设置图表样式\n",
                "plt.style.use('seaborn-v0_8')\n",
                "sns.set_palette(\"husl\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. 数据加载与概览"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 加载清洗后的数据\n",
                "data_path = Path('../data/processed/hernia_clean.csv')\n",
                "df = pd.read_csv(data_path)\n",
                "\n",
                "print(f\"数据形状: {df.shape}\")\n",
                "print(f\"列数: {df.shape[1]}\")\n",
                "print(f\"行数: {df.shape[0]}\")\n",
                "\n",
                "# 数据概览\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"数据概览\")\n",
                "print(\"=\"*60)\n",
                "print(f\"总样本数: {df.shape[0]:,}\")\n",
                "print(f\"总特征数: {df.shape[1]:,}\")\n",
                "print(f\"数值特征数: {df.select_dtypes(include=[np.number]).shape[1]}\")\n",
                "print(f\"分类特征数: {df.select_dtypes(include=['object']).shape[1]}\")\n",
                "\n",
                "# 显示前几列和后几列\n",
                "print(\"\\n前5列:\", list(df.columns[:5]))\n",
                "print(\"后5列:\", list(df.columns[-5:]))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. 数据质量统计"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 数据质量统计\n",
                "print(\"=\"*60)\n",
                "print(\"数据质量统计\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# 缺失值统计\n",
                "missing_data = df.isnull().sum()\n",
                "missing_percentage = (missing_data / len(df)) * 100\n",
                "\n",
                "print(f\"\\n缺失值统计:\")\n",
                "print(f\"无缺失值的列数: {(missing_data == 0).sum()}\")\n",
                "print(f\"有缺失值的列数: {(missing_data > 0).sum()}\")\n",
                "\n",
                "if (missing_data > 0).sum() > 0:\n",
                "    print(\"\\n缺失值最多的前10列:\")\n",
                "    missing_summary = pd.DataFrame({\n",
                "        '列名': missing_data[missing_data > 0].index,\n",
                "        '缺失数量': missing_data[missing_data > 0].values,\n",
                "        '缺失比例(%)': missing_percentage[missing_data > 0].values\n",
                "    }).sort_values('缺失数量', ascending=False).head(10)\n",
                "    print(missing_summary)\n",
                "else:\n",
                "    print(\"\\n✅ 所有列均无缺失值\")\n",
                "\n",
                "# 数据类型统计\n",
                "print(f\"\\n数据类型统计:\")\n",
                "dtype_counts = df.dtypes.value_counts()\n",
                "for dtype, count in dtype_counts.items():\n",
                "    print(f\"  {dtype}: {count}列\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. 目标变量分析 (duration_min)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 目标变量分析\n",
                "target_col = 'duration_min'\n",
                "\n",
                "print(f\"目标变量 '{target_col}' 详细统计:\")\n",
                "print(\"=\"*50)\n",
                "print(df[target_col].describe())\n",
                "\n",
                "# 异常值检查\n",
                "print(f\"\\n异常值检查:\")\n",
                "print(f\"0分钟记录数: {(df[target_col] == 0).sum()}\")\n",
                "print(f\"超过300分钟记录数: {(df[target_col] > 300).sum()}\")\n",
                "print(f\"超过400分钟记录数: {(df[target_col] > 400).sum()}\")\n",
                "print(f\"超过500分钟记录数: {(df[target_col] > 500).sum()}\")\n",
                "\n",
                "# 分布偏度分析\n",
                "from scipy import stats\n",
                "skewness = stats.skew(df[target_col].dropna())\n",
                "print(f\"\\n分布偏度: {skewness:.3f}\")\n",
                "if abs(skewness) > 1:\n",
                "    print(\"⚠️  分布严重偏斜，建议使用log1p变换\")\n",
                "elif abs(skewness) > 0.5:\n",
                "    print(\"⚠️  分布中等偏斜，可考虑log1p变换\")\n",
                "else:\n",
                "    print(\"✅ 分布相对对称\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 目标变量分布可视化\n",
                "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
                "fig.suptitle('手术时长分布分析', fontsize=16, fontweight='bold')\n",
                "\n",
                "# 1. 原始数据直方图\n",
                "axes[0, 0].hist(df[target_col], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
                "axes[0, 0].set_title('原始手术时长分布')\n",
                "axes[0, 0].set_xlabel('时长（分钟）')\n",
                "axes[0, 0].set_ylabel('频次')\n",
                "axes[0, 0].axvline(df[target_col].mean(), color='red', linestyle='--', \n",
                "                    label=f'均值: {df[target_col].mean():.1f}')\n",
                "axes[0, 0].axvline(df[target_col].median(), color='green', linestyle='--', \n",
                "                    label=f'中位数: {df[target_col].median():.1f}')\n",
                "axes[0, 0].legend()\n",
                "\n",
                "# 2. 原始数据箱线图\n",
                "axes[0, 1].boxplot(df[target_col])\n",
                "axes[0, 1].set_title('原始手术时长箱线图')\n",
                "axes[0, 1].set_ylabel('时长（分钟）')\n",
                "\n",
                "# 3. 原始数据Q-Q图\n",
                "from scipy import stats\n",
                "stats.probplot(df[target_col].dropna(), dist=\"norm\", plot=axes[0, 2])\n",
                "axes[0, 2].set_title('原始数据Q-Q图（正态性检验）')\n",
                "\n",
                "# 4. log1p变换后的直方图\n",
                "log_duration = np.log1p(df[target_col])\n",
                "axes[1, 0].hist(log_duration, bins=50, alpha=0.7, color='lightgreen', edgecolor='black')\n",
                "axes[1, 0].set_title('log1p变换后分布')\n",
                "axes[1, 0].set_xlabel('log1p(时长)')\n",
                "axes[1, 0].set_ylabel('频次')\n",
                "axes[1, 0].axvline(log_duration.mean(), color='red', linestyle='--', \n",
                "                    label=f'均值: {log_duration.mean():.3f}')\n",
                "axes[1, 0].legend()\n",
                "\n",
                "# 5. log1p变换后的箱线图\n",
                "axes[1, 1].boxplot(log_duration)\n",
                "axes[1, 1].set_title('log1p变换后箱线图')\n",
                "axes[1, 1].set_ylabel('log1p(时长)')\n",
                "\n",
                "# 6. log1p变换后的Q-Q图\n",
                "stats.probplot(log_duration.dropna(), dist=\"norm\", plot=axes[1, 2])\n",
                "axes[1, 2].set_title('log1p变换后Q-Q图')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# 变换前后偏度对比\n",
                "print(f\"\\n变换前后偏度对比:\")\n",
                "print(f\"原始数据偏度: {stats.skew(df[target_col].dropna()):.3f}\")\n",
                "print(f\"log1p变换后偏度: {stats.skew(log_duration.dropna()):.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. 时间特征分析"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 时间特征分析\n",
                "time_features = [col for col in df.columns if 'op_startdttm_fix' in col and col != 'op_startdttm_fix']\n",
                "print(f\"时间特征列: {time_features}\")\n",
                "\n",
                "# 手术时间分布\n",
                "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
                "fig.suptitle('手术时间分布分析', fontsize=16, fontweight='bold')\n",
                "\n",
                "# 小时分布\n",
                "hour_counts = df['op_startdttm_fix_hour'].value_counts().sort_index()\n",
                "axes[0, 0].bar(hour_counts.index, hour_counts.values, color='skyblue', alpha=0.7)\n",
                "axes[0, 0].set_title('手术开始时间分布（小时）')\n",
                "axes[0, 0].set_xlabel('小时')\n",
                "axes[0, 0].set_ylabel('手术数量')\n",
                "\n",
                "# 星期分布\n",
                "day_counts = df['op_startdttm_fix_day_of_week'].value_counts().sort_index()\n",
                "day_labels = ['周一', '周二', '周三', '周四', '周五', '周六', '周日']\n",
                "axes[0, 1].bar(range(len(day_counts)), day_counts.values, color='lightgreen', alpha=0.7)\n",
                "axes[0, 1].set_title('手术开始时间分布（星期）')\n",
                "axes[0, 1].set_xlabel('星期')\n",
                "axes[0, 1].set_ylabel('手术数量')\n",
                "axes[0, 1].set_xticks(range(len(day_labels)))\n",
                "axes[0, 1].set_xticklabels(day_labels)\n",
                "\n",
                "# 月份分布\n",
                "month_counts = df['op_startdttm_fix_month'].value_counts().sort_index()\n",
                "axes[0, 2].bar(month_counts.index, month_counts.values, color='orange', alpha=0.7)\n",
                "axes[0, 2].set_title('手术开始时间分布（月份）')\n",
                "axes[0, 2].set_xlabel('月份')\n",
                "axes[0, 2].set_ylabel('手术数量')\n",
                "\n",
                "# 时间段分布\n",
                "time_of_day_counts = df['op_startdttm_fix_time_of_day'].value_counts()\n",
                "axes[1, 0].bar(range(len(time_of_day_counts)), time_of_day_counts.values, \n",
                "               color=['red', 'orange', 'yellow', 'blue'], alpha=0.7)\n",
                "axes[1, 0].set_title('手术开始时间分布（时间段）')\n",
                "axes[1, 0].set_xlabel('时间段')\n",
                "axes[1, 0].set_ylabel('手术数量')\n",
                "axes[1, 0].set_xticks(range(len(time_of_day_counts)))\n",
                "axes[1, 0].set_xticklabels(time_of_day_counts.index)\n",
                "\n",
                "# 周末vs工作日\n",
                "weekend_counts = df['op_startdttm_fix_is_weekend'].value_counts()\n",
                "axes[1, 1].pie(weekend_counts.values, labels=['工作日', '周末'], autopct='%1.1f%%', \n",
                "               colors=['lightblue', 'lightcoral'])\n",
                "axes[1, 1].set_title('周末vs工作日手术比例')\n",
                "\n",
                "# 季度分布\n",
                "quarter_counts = df['op_startdttm_fix_quarter'].value_counts().sort_index()\n",
                "axes[1, 2].bar(quarter_counts.index, quarter_counts.values, color='purple', alpha=0.7)\n",
                "axes[1, 2].set_title('手术开始时间分布（季度）')\n",
                "axes[1, 2].set_xlabel('季度')\n",
                "axes[1, 2].set_ylabel('手术数量')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. 数值特征相关性分析"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 数值特征相关性分析\n",
                "print(\"=\"*60)\n",
                "print(\"数值特征相关性分析\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# 选择主要数值特征\n",
                "main_numeric_features = ['duration_min', 'AgeAtSurgery', 'BMI', 'Weight_Value', \n",
                "                        'EG_CharlsScore', 'NRTN_Score', 'num_surg_anes_worked']\n",
                "available_numeric = [f for f in main_numeric_features if f in df.columns]\n",
                "\n",
                "print(f\"可用数值特征: {available_numeric}\")\n",
                "\n",
                "if len(available_numeric) > 1:\n",
                "    # 计算相关性矩阵\n",
                "    correlation_data = df[available_numeric].corr()\n",
                "    \n",
                "    # 皮尔森相关性\n",
                "    print(f\"\\n皮尔森相关性矩阵:\")\n",
                "    print(correlation_data.round(3))\n",
                "    \n",
                "    # 斯皮尔曼相关性\n",
                "    spearman_corr = df[available_numeric].corr(method='spearman')\n",
                "    print(f\"\\n斯皮尔曼相关性矩阵:\")\n",
                "    print(spearman_corr.round(3))\n",
                "    \n",
                "    # 与目标变量的相关性排序\n",
                "    target_corr_pearson = correlation_data['duration_min'].sort_values(ascending=False)\n",
                "    target_corr_spearman = spearman_corr['duration_min'].sort_values(ascending=False)\n",
                "    \n",
                "    print(f\"\\n与手术时长的相关性排序:\")\n",
                "    print(\"\\n皮尔森相关性:\")\n",
                "    for feature, corr in target_corr_pearson.items():\n",
                "        print(f\"  {feature}: {corr:.3f}\")\n",
                "    \n",
                "    print(\"\\n斯皮尔曼相关性:\")\n",
                "    for feature, corr in target_corr_spearman.items():\n",
                "        print(f\"  {feature}: {corr:.3f}\")\n",
                "else:\n",
                "    print(\"可用数值特征不足，无法进行相关性分析\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 相关性热力图可视化\n",
                "if len(available_numeric) > 1:\n",
                "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
                "    \n",
                "    # 皮尔森相关性热力图\n",
                "    sns.heatmap(correlation_data, annot=True, cmap='coolwarm', center=0, \n",
                "                square=True, fmt='.3f', ax=axes[0])\n",
                "    axes[0].set_title('皮尔森相关性热力图')\n",
                "    \n",
                "    # 斯皮尔曼相关性热力图\n",
                "    sns.heatmap(spearman_corr, annot=True, cmap='coolwarm', center=0, \n",
                "                square=True, fmt='.3f', ax=axes[1])\n",
                "    axes[1].set_title('斯皮尔曼相关性热力图')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    # 散点图矩阵\n",
                "    if len(available_numeric) <= 6:  # 避免图表过于复杂\n",
                "        sns.pairplot(df[available_numeric], diag_kind='kde')\n",
                "        plt.suptitle('主要特征散点图矩阵', y=1.02)\n",
                "        plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. 分类特征分析"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 分类特征分析\n",
                "print(\"=\"*60)\n",
                "print(\"分类特征分析\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# 选择主要分类特征\n",
                "main_categorical_features = ['SexCode', 'UrgencyFLG', 'General_anesthesia', \n",
                "                            'Regional_anesthesia', 'Diabetes_Flg']\n",
                "available_categorical = [f for f in main_categorical_features if f in df.columns]\n",
                "\n",
                "print(f\"可用分类特征: {available_categorical}\")\n",
                "\n",
                "# 分析每个分类特征\n",
                "for feature in available_categorical:\n",
                "    print(f\"\\n{feature}:\")\n",
                "    value_counts = df[feature].value_counts()\n",
                "    print(f\"  唯一值数: {len(value_counts)}\")\n",
                "    print(f\"  前5个值:\")\n",
                "    for value, count in value_counts.head().items():\n",
                "        percentage = (count / len(df)) * 100\n",
                "        print(f\"    {value}: {count} ({percentage:.1f}%)\")\n",
                "    \n",
                "    # 检查类别不平衡\n",
                "    if len(value_counts) > 2:\n",
                "        min_count = value_counts.min()\n",
                "        if min_count < 20:\n",
                "            print(f\"  ⚠️  存在稀有类别 (频次 < 20)，建议合并为 'rare_{feature}'\")\n",
                "    \n",
                "    # 与目标变量的关系\n",
                "    if feature != 'duration_min':\n",
                "        print(f\"  与手术时长的关系:\")\n",
                "        group_stats = df.groupby(feature)['duration_min'].agg(['mean', 'std', 'count'])\n",
                "        print(group_stats.round(2))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. 数据泄漏检查"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 数据泄漏检查\n",
                "print(\"=\"*60)\n",
                "print(\"数据泄漏检查\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# 检查是否存在事后变量\n",
                "suspicious_features = [col for col in df.columns if any(keyword in col.lower() \n",
                "                                                    for keyword in ['result', 'outcome', 'complication', \n",
                "                                                                 'post', 'after', 'final'])]\n",
                "print(f\"\\n可疑的事后变量:\")\n",
                "if suspicious_features:\n",
                "    for feature in suspicious_features:\n",
                "        print(f\"  ⚠️  {feature}\")\n",
                "    print(\"\\n⚠️  这些特征可能包含数据泄漏，需要仔细检查！\")\n",
                "else:\n",
                "    print(\"  ✅ 未发现明显的事后变量\")\n",
                "\n",
                "# 检查患者ID和术者ID\n",
                "id_features = [col for col in df.columns if any(keyword in col.lower() \n",
                "                                              for keyword in ['id', 'hash', 'patient', 'surgeon', 'doc'])]\n",
                "print(f\"\\nID相关特征:\")\n",
                "for feature in id_features:\n",
                "    unique_count = df[feature].nunique()\n",
                "    total_count = len(df)\n",
                "    print(f\"  {feature}: {unique_count} 个唯一值 / {total_count} 总记录\")\n",
                "    \n",
                "    if unique_count < total_count * 0.9:  # 如果唯一值比例过高，可能是ID\n",
                "        print(f\"    ⚠️  可能是ID特征，需要分组切分避免数据泄漏\")\n",
                "    \n",
                "    # 检查同一ID的记录分布\n",
                "    if unique_count < 100:  # 如果唯一值不太多，显示分布\n",
                "        id_counts = df[feature].value_counts()\n",
                "        print(f\"    记录数最多的前5个ID:\")\n",
                "        for id_val, count in id_counts.head().items():\n",
                "            print(f\"      {id_val}: {count} 条记录\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. 评估指标定义"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 评估指标定义\n",
                "print(\"=\"*60)\n",
                "print(\"评估指标定义\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, median_absolute_error\n",
                "\n",
                "def calculate_metrics(y_true, y_pred, log_transformed=False):\n",
                "    \"\"\"\n",
                "    计算评估指标\n",
                "    \n",
                "    Args:\n",
                "        y_true: 真实值\n",
                "        y_pred: 预测值\n",
                "        log_transformed: 是否使用了log1p变换\n",
                "    \n",
                "    Returns:\n",
                "        dict: 包含各种评估指标的字典\n",
                "    \"\"\"\n",
                "    \n",
                "    # 如果使用了log1p变换，需要还原\n",
                "    if log_transformed:\n",
                "        y_true_original = np.expm1(y_true)\n",
                "        y_pred_original = np.expm1(y_pred)\n",
                "    else:\n",
                "        y_true_original = y_true\n",
                "        y_pred_original = y_pred\n",
                "    \n",
                "    metrics = {\n",
                "        'MAE (分钟)': mean_absolute_error(y_true_original, y_pred_original),\n",
                "        'RMSE (分钟)': np.sqrt(mean_squared_error(y_true_original, y_pred_original)),\n",
                "        'R²': r2_score(y_true_original, y_pred_original),\n",
                "        'MedAE (分钟)': median_absolute_error(y_true_original, y_pred_original)\n",
                "    }\n",
                "    \n",
                "    return metrics\n",
                "\n",
                "print(\"\\n主要评估指标:\")\n",
                "print(\"1. MAE (Mean Absolute Error): 平均绝对误差，单位：分钟\")\n",
                "print(\"   - 主要评估指标，直观反映预测误差\")\n",
                "print(\"   - 对异常值相对鲁棒\")\n",
                "\n",
                "print(\"\\n2. RMSE (Root Mean Square Error): 均方根误差，单位：分钟\")\n",
                "print(\"   - 辅助评估指标，对异常值敏感\")\n",
                "print(\"   - 可用于比较不同模型的性能\")\n",
                "\n",
                "print(\"\\n3. R² (R-squared): 决定系数\")\n",
                "print(\"   - 解释方差的比例，范围[0,1]\")\n",
                "print(\"   - 越接近1表示模型解释能力越强\")\n",
                "\n",
                "print(\"\\n4. MedAE (Median Absolute Error): 中位绝对误差，单位：分钟\")\n",
                "print(\"   - 抗离群值指标，对异常值鲁棒\")\n",
                "print(\"   - 反映典型预测误差水平\")\n",
                "\n",
                "print(\"\\n⚠️  重要提醒:\")\n",
                "print(\"如果使用log1p(duration)训练，推断后必须用expm1()还原，再计算分钟单位的MAE！\")\n",
                "print(\"这样可以保持评估指标的一致性和可解释性。\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. 数据质量总结与建议"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 数据质量总结\n",
                "print(\"=\"*60)\n",
                "print(\"数据质量总结与建议\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "print(f\"\\n1. 数据规模:\")\n",
                "print(f\"   - 样本数: {df.shape[0]:,}\")\n",
                "print(f\"   - 特征数: {df.shape[1]:,}\")\n",
                "print(f\"   - 目标变量: {target_col}\")\n",
                "\n",
                "print(f\"\\n2. 目标变量特征:\")\n",
                "print(f\"   - 均值: {df[target_col].mean():.2f} 分钟\")\n",
                "print(f\"   - 标准差: {df[target_col].std():.2f} 分钟\")\n",
                "print(f\"   - 中位数: {df[target_col].median():.2f} 分钟\")\n",
                "print(f\"   - 范围: {df[target_col].min():.1f} - {df[target_col].max():.1f} 分钟\")\n",
                "print(f\"   - 偏度: {stats.skew(df[target_col].dropna()):.3f}\")\n",
                "\n",
                "print(f\"\\n3. 数据完整性:\")\n",
                "missing_count = df.isnull().sum().sum()\n",
                "if missing_count == 0:\n",
                "    print(f\"   ✅ 无缺失值\")\n",
                "else:\n",
                "    print(f\"   ⚠️  存在 {missing_count} 个缺失值\")\n",
                "\n",
                "print(f\"\\n4. 时间特征:\")\n",
                "print(f\"   - 基于手术开始时间创建了6个派生特征\")\n",
                "print(f\"   - 手术时间分布: 主要集中在工作时间\")\n",
                "\n",
                "print(f\"\\n5. 潜在问题:\")\n",
                "print(f\"   - 存在0分钟手术记录，需要临床验证\")\n",
                "print(f\"   - 特征数量较多(1,727个)，需要特征选择\")\n",
                "print(f\"   - 目标变量分布偏斜，建议使用log1p变换\")\n",
                "\n",
                "print(f\"\\n6. 建模建议:\")\n",
                "print(f\"   - 对0分钟记录进行临床合理性检查\")\n",
                "print(f\"   - 进行特征重要性分析，选择关键特征\")\n",
                "print(f\"   - 考虑时间特征对手术时长的影响\")\n",
                "print(f\"   - 对高基数类别变量进行编码处理\")\n",
                "print(f\"   - 使用log1p变换处理目标变量偏斜\")\n",
                "print(f\"   - 对稀有类别进行合并处理\")\n",
                "print(f\"   - 检查并避免数据泄漏\")\n",
                "\n",
                "print(f\"\\n7. 评估策略:\")\n",
                "print(f\"   - 主要指标: MAE (分钟)\")\n",
                "print(f\"   - 辅助指标: RMSE、R²、MedAE\")\n",
                "print(f\"   - 使用时间序列分割避免数据泄漏\")\n",
                "print(f\"   - 如果使用log1p变换，必须用expm1还原后计算指标\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}

# 写入文件
with open('notebooks/01_eda.ipynb', 'w', encoding='utf-8') as f:
    json.dump(notebook_content, f, ensure_ascii=False, indent=2)

print("完整EDA笔记本创建成功！")
